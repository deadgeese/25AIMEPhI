{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/classification-of-oil-and-gas/data\n",
    "по различным параметрам определять местонахождение залежей нефти и газа: 0: OFFSHORE (морское), 1: ONSHORE (на суше), 2: ONSHORE-OFFSHORE (смешанное)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_path = r'C:\\study-1\\Proga-5\\5_ml\\train_oil.csv'\n",
    "test_path = r'C:\\study-1\\Proga-5\\5_ml\\oil_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(f\"Размер тренировочных данных: {train_df.shape}\")\n",
    "print(f\"Размер тестовых данных: {test_df.shape}\")\n",
    "\n",
    "# Предобработка данных\n",
    "def preprocess_data(df, is_train=True, label_encoders=None):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Создаем копию целевой переменной для тренировочных данных\n",
    "    if is_train:\n",
    "        target = df_processed['Onshore/Offshore'].copy()\n",
    "        #Для тренировочных данных: извлекаем целевую переменную и удаляем ее из признаков\n",
    "        df_processed = df_processed.drop('Onshore/Offshore', axis=1)\n",
    "    else:\n",
    "        target = None\n",
    "    \n",
    "    # Преобразуем текстовые метки в числа\n",
    "    if is_train:\n",
    "        target_encoded = target.map({'ONSHORE': 1, 'OFFSHORE': 0, 'ONSHORE-OFFSHORE': 2})\n",
    "    else:\n",
    "        target_encoded = None\n",
    "    \n",
    "    # Список категориальных колонок для кодирования\n",
    "    categorical_cols = [\n",
    "        'Field name', 'Reservoir unit', 'Country', 'Region', 'Basin name', \n",
    "        'Tectonic regime', 'Operator company', 'Hydrocarbon type', \n",
    "        'Reservoir status', 'Structural setting', 'Reservoir period', 'Lithology'\n",
    "    ]\n",
    "    \n",
    "    # Создаем новый энкодер для каждого категориального столбца. обучает энкодер и преобразует данные\n",
    "    if is_train:\n",
    "        label_encoders = {}\n",
    "        for col in categorical_cols:\n",
    "            if col in df_processed.columns:\n",
    "                le = LabelEncoder()\n",
    "                # Заполняем пропуски перед кодированием\n",
    "                df_processed[col] = df_processed[col].fillna('Unknown')\n",
    "                df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "                label_encoders[col] = le\n",
    "    else:\n",
    "        # Используем существующие энкодеры для тестовых данных\n",
    "        for col in categorical_cols:\n",
    "            if col in df_processed.columns and col in label_encoders:\n",
    "                df_processed[col] = df_processed[col].fillna('Unknown')\n",
    "                try:\n",
    "                    #только преобразуем данные (не обучаем заново)\n",
    "                    df_processed[col] = label_encoders[col].transform(df_processed[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # Для новых категорий используем -1\n",
    "                    df_processed[col] = -1\n",
    "    \n",
    "    # Обработка числовых колонок\n",
    "    numeric_cols = ['Latitude', 'Longitude', 'Depth', 'Thickness (gross average ft)', \n",
    "                   'Thickness (net pay average ft)', 'Porosity', 'Permeability']\n",
    "    \n",
    "    # Заполняем пропуски в числовых колонках\n",
    "    for col in numeric_cols:\n",
    "        if col in df_processed.columns:\n",
    "            #преобразует в числа, нечисловые значения становятся NaN\n",
    "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "            if is_train:\n",
    "                # заполняет пропуски медианным значением столбца\n",
    "                imputer = SimpleImputer(strategy='median')\n",
    "                df_processed[col] = imputer.fit_transform(df_processed[[col]]).ravel()\n",
    "            else:\n",
    "                imputer = SimpleImputer(strategy='median')\n",
    "                df_processed[col] = imputer.fit_transform(df_processed[[col]]).ravel()\n",
    "    \n",
    "    return df_processed, target_encoded, label_encoders if is_train else (df_processed, target_encoded)\n",
    "\n",
    "# Предобработка тренировочных данных\n",
    "X_train_processed, y_train, label_encoders = preprocess_data(train_df, is_train=True)\n",
    "\n",
    "# Предобработка тестовых данных\n",
    "X_test_processed, y_test, _ = preprocess_data(test_df, is_train=False, label_encoders=label_encoders)\n",
    "\n",
    "# Выравнивание колонок\n",
    "common_cols = list(set(X_train_processed.columns) & set(X_test_processed.columns))\n",
    "X_train_final = X_train_processed[common_cols]\n",
    "X_test_final = X_test_processed[common_cols]\n",
    "\n",
    "# Масштабирование числовых признаков\n",
    "scaler = StandardScaler()\n",
    "numeric_cols_final = [col for col in common_cols if col in ['Latitude', 'Longitude', 'Depth', \n",
    "                                                          'Thickness (gross average ft)', \n",
    "                                                          'Thickness (net pay average ft)', \n",
    "                                                          'Porosity', 'Permeability']]\n",
    "\n",
    "X_train_final[numeric_cols_final] = scaler.fit_transform(X_train_final[numeric_cols_final])\n",
    "X_test_final[numeric_cols_final] = scaler.transform(X_test_final[numeric_cols_final])\n",
    "\n",
    "# Разделение тренировочных данных для валидации\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_final, y_train, test_size=0.2, \n",
    "                                          random_state=42, stratify=y_train)\n",
    "\n",
    "# Обучение модели\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,      \n",
    "    max_depth=15,          \n",
    "    min_samples_split=5,  \n",
    "    min_samples_leaf=2,    \n",
    "    random_state=42,       \n",
    "    class_weight='balanced' \n",
    ")\n",
    "\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "# Предсказание на валидационной выборке \n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Оценка модели\n",
    "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "print(f\"\\nF1-score на валидации: {f1:.4f}\")\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Обучение на всех тренировочных данных\n",
    "model_final = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model_final.fit(X_train_final, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "test_predictions = model_final.predict(X_test_final)\n",
    "\n",
    "# Создание файла с предсказаниями\n",
    "submission = pd.DataFrame({\n",
    "    'index': range(len(test_predictions)),\n",
    "    'Onshore/Offshore': test_predictions\n",
    "})\n",
    "\n",
    "# Сохранение результатов\n",
    "output_path = r'C:\\study-1\\Proga-5\\5_ml\\submission.csv'\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "# Анализ важности признаков\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_final.columns,\n",
    "    'importance': model_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
